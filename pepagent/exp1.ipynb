{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Agent-based peptide discovery"
  },
  {
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:07.171437Z",
     "start_time": "2025-10-31T08:37:06.082910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import autogen\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import openai\n",
    "from openai import AsyncOpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from IPython.display import Markdown, display\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:11.350653Z",
     "start_time": "2025-10-31T08:37:10.518195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:13.566603Z",
     "start_time": "2025-10-31T08:37:12.858414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Credentials are read from environment variables.\n",
    "# See the repo root `.env.example` (copy to `.env`, do not commit).\n",
    "\n",
    "# Optional: Hugging Face token (needed for some gated models).\n",
    "try:\n",
    "    from huggingface_hub import login\n",
    "except Exception:\n",
    "    login = None\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if hf_token and login:\n",
    "    login(token=hf_token)\n",
    "elif hf_token and not login:\n",
    "    print('HF_TOKEN is set but `huggingface_hub` is not installed; skipping login.')\n",
    "else:\n",
    "    print('HF_TOKEN not set; skipping Hugging Face login.')\n",
    "\n",
    "# OpenAI/AutoGen expects OPENAI_API_KEY in the environment.\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    raise RuntimeError('OPENAI_API_KEY is not set. See `.env.example`.')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Using GPT-4 - Main setup starts here"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:15.424306Z",
     "start_time": "2025-10-31T08:37:15.420687Z"
    }
   },
   "source": [
    "device = \"cpu\"\n",
    "import transformers\n",
    "autogen.__version__, openai.__version__, transformers.__version__ #make sure to update both autogen and openai to their newsest versions \n",
    "# ('0.2.2', '1.6.0', '4.35.1')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:18.960304Z",
     "start_time": "2025-10-31T08:37:18.220395Z"
    }
   },
   "source": [
    "from llm_config import llm_config\n",
    "from llm_config import config_list\n",
    "import agent_functions as func\n",
    "import agents\n",
    "import autogen"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:37:20.492197Z",
     "start_time": "2025-10-31T08:37:20.454900Z"
    }
   },
   "source": [
    "def _reset_agents():\n",
    "    agents.user_proxy.reset()\n",
    "    #agents.ragproxyagent.reset()\n",
    "    agents.planner.reset()\n",
    "    agents.assistant.reset()\n",
    "    agents.critic.reset()\n",
    "    #agents.reviewer.reset()\n",
    "    #agents.coder.reset()\n",
    "    #agents.executor.reset()\n",
    "    #sequence_retriever.reset()\n",
    "#manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "_reset_agents()\n",
    "\n",
    "manager_llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": 45,\n",
    "}\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[agents.user_proxy, agents.planner, agents.assistant, agents.critic, #agents.coder, agents.executor  #sequence_retriever,\n",
    "               ], messages=[], max_round=150, \n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config = manager_llm_config, \n",
    "                system_message='This agent repeats the following steps: Dynamically selecting a speaker, collecting response, and \\\n",
    "broadcasting the message to the group.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:38:51.185261Z",
     "start_time": "2025-10-31T08:37:28.162450Z"
    }
   },
   "source": [
    "# agents.user_proxy.initiate_chat(\n",
    "#     recipient=manager,\n",
    "#     message='''\n",
    "# Can you provide some names of antimicrobial resistant bacteria?\n",
    "# '''\n",
    "# )\n",
    "agents.user_proxy.initiate_chat(\n",
    "    recipient=manager,\n",
    "    message='''\n",
    "For the local file \"smorfs_10_50aa.faa\" in the workspace containing small open reading frame (smORF)sequences, can you discover AMPs (antimicrobial peptides) that are effective and safe to use against the antimicrobial resistant fungi Fusarium oxysporum?\n",
    "'''\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T08:50:12.051081Z",
     "start_time": "2025-10-31T08:48:56.659675Z"
    }
   },
   "source": [
    "agents.user_proxy.send(\n",
    "    recipient=manager,\n",
    "    message='''Can you fetch verfied AMPs from the database that might be effective against Fusarium oxysporum, and for the predicted results in \"amp_mic_tox_hemo.csv\" you provided that are effective and safe to use against the antimicrobial resistant fungi Fusarium oxysporum, can you further filter the most promising AMP candidates in \"amp_mic_tox_hemo.csv\" by getting similarity scores against the verfied AMPs you fetched from the database?\n",
    "    '''\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
